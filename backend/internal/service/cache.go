package service

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"strings"
	"time"

	"embyforge/internal/emby"
	"embyforge/internal/model"

	"gorm.io/gorm"
	"gorm.io/gorm/clause"
)

// SyncResult åŒæ­¥ç»“æœ
type SyncResult struct {
	TotalItems   int   `json:"total_items"`
	TotalSeasons int   `json:"total_seasons"`
	ElapsedMs    int64 `json:"elapsed_ms"`
}

// SyncProgress åŒæ­¥è¿›åº¦äº‹ä»¶
type SyncProgress struct {
	Phase     string      `json:"phase"`               // "media" æˆ– "season"
	Processed int         `json:"processed"`            // å·²å¤„ç†æ¡ç›®æ•°
	Total     int         `json:"total"`                // æ€»æ¡ç›®æ•°
	Done      bool        `json:"done"`                 // æ˜¯å¦å®Œæˆ
	Error     string      `json:"error,omitempty"`      // é”™è¯¯ä¿¡æ¯
	Result    *SyncResult `json:"result,omitempty"`     // å®Œæˆæ—¶çš„ç»“æœ
}

// CacheService åª’ä½“ç¼“å­˜æœåŠ¡
type CacheService struct {
	DB *gorm.DB
}

// NewCacheService åˆ›å»ºç¼“å­˜æœåŠ¡
func NewCacheService(db *gorm.DB) *CacheService {
	return &CacheService{DB: db}
}

// SyncMediaCache ä» Emby åŒæ­¥å®Œæ•´åª’ä½“åº“åˆ°æœ¬åœ°ç¼“å­˜
// æµç¨‹ï¼šæ¸…ç©ºç¼“å­˜è¡¨ â†’ åˆ†é¡µè·å– Emby åª’ä½“ â†’ æ‰¹é‡å†™å…¥ media_cache â†’ è·å– Series çš„å­£ä¿¡æ¯ â†’ å†™å…¥ season_cache
func (s *CacheService) SyncMediaCache(client *emby.Client) (*SyncResult, error) {
	start := time.Now()

	// æ¸…ç©ºç¼“å­˜è¡¨
	if err := s.DB.Exec("DELETE FROM media_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºåª’ä½“ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	log.Printf("ğŸ—‘ï¸ å·²æ¸…ç©ºç¼“å­˜è¡¨")

	result := &SyncResult{}

	// åˆ†é¡µè·å–æ‰€æœ‰åª’ä½“æ¡ç›®å¹¶å†™å…¥ç¼“å­˜ï¼ˆåªæ‹‰å– Movie/Series/Episodeï¼‰
	err := client.GetMediaItems(emby.SyncItemTypes, func(items []emby.MediaItem) error {
		caches := make([]model.MediaCache, 0, len(items))
		for _, item := range items {
			cache := model.NewMediaCacheFromItem(item, "")
			caches = append(caches, cache)
		}

		if len(caches) > 0 {
			if err := s.DB.Clauses(clause.OnConflict{
				Columns:   []clause.Column{{Name: "emby_item_id"}},
				DoUpdates: clause.AssignmentColumns([]string{"name", "type", "has_poster", "path", "provider_ids", "file_size", "index_number", "parent_index_number", "child_count", "series_id", "series_name", "library_name", "cached_at"}),
			}).Create(&caches).Error; err != nil {
				log.Printf("æ‰¹é‡å†™å…¥åª’ä½“ç¼“å­˜å¤±è´¥ï¼Œå°è¯•é€æ¡å†™å…¥: %v", err)
				for _, c := range caches {
					if err := s.DB.Clauses(clause.OnConflict{
						Columns:   []clause.Column{{Name: "emby_item_id"}},
						DoUpdates: clause.AssignmentColumns([]string{"name", "type", "has_poster", "path", "provider_ids", "file_size", "index_number", "parent_index_number", "child_count", "series_id", "series_name", "library_name", "cached_at"}),
					}).Create(&c).Error; err != nil {
						log.Printf("å†™å…¥åª’ä½“ç¼“å­˜è®°å½•å¤±è´¥ (EmbyItemID=%s): %v", c.EmbyItemID, err)
						continue
					}
				}
			}
			result.TotalItems += len(caches)
		}

		log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜åŒæ­¥: å·²å¤„ç† %d ä¸ªæ¡ç›®...", result.TotalItems)
		return nil
	})

	if err != nil {
		return nil, fmt.Errorf("è·å– Emby åª’ä½“æ¡ç›®å¤±è´¥: %w", err)
	}

	// ç›´æ¥ä»å·²åŒæ­¥çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜ï¼ˆé›¶é¢å¤– HTTP è¯·æ±‚ï¼‰
	sqlDB, dbErr := s.DB.DB()
	if dbErr != nil {
		log.Printf("âš ï¸ è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", dbErr)
	} else {
		seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
		if err != nil {
			log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
		} else {
			result.TotalSeasons = seasonCount
		}
	}

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… åª’ä½“ç¼“å­˜åŒæ­¥å®Œæˆ: %d ä¸ªåª’ä½“æ¡ç›®, %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.TotalSeasons, result.ElapsedMs)

	return result, nil
}

// syncBatchSize å†…å­˜ç¼“å†²åŒºæ»¡åæ‰¹é‡å†™å…¥æ•°æ®åº“çš„æ¡ç›®æ•°
const syncBatchSize = 10000

// SyncMediaCacheWithContext ä½¿ç”¨ Worker Pool çš„ç¼“å­˜åŒæ­¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰
// ä¼˜åŒ–ç­–ç•¥ï¼š
//   - å¢å¤§ API é¡µé¢å¤§å°å‡å°‘ HTTP è¯·æ±‚æ¬¡æ•°
//   - å†…å­˜å»é‡é¿å… Emby API è¿”å›çš„é‡å¤æ¡ç›®
//   - å…ˆ DELETE å†çº¯ INSERTï¼ˆæ— éœ€ ON CONFLICT å¼€é”€ï¼‰
//   - å¤§æ‰¹é‡äº‹åŠ¡å†™å…¥å‡å°‘ SQLite äº‹åŠ¡å¼€é”€
func (s *CacheService) SyncMediaCacheWithContext(ctx context.Context, client *emby.Client) (*SyncResult, error) {
	start := time.Now()

	// æ£€æŸ¥ context æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return nil, ctx.Err()
	default:
	}

	// æ¸…ç©ºç¼“å­˜è¡¨
	if err := s.DB.Exec("DELETE FROM media_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºåª’ä½“ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	log.Printf("ğŸ—‘ï¸ å·²æ¸…ç©ºç¼“å­˜è¡¨")

	result := &SyncResult{}

	// å†…å­˜å»é‡é›†åˆï¼ŒEmby API è·¨é¡µå¯èƒ½è¿”å›é‡å¤ item
	seen := make(map[string]bool, 300000)
	// å†…å­˜ç¼“å†²åŒºï¼Œæ”’å¤Ÿ syncBatchSize æ¡åæ‰¹é‡å†™å…¥
	buffer := make([]model.MediaCache, 0, syncBatchSize)

	// flushBuffer å°†ç¼“å†²åŒºæ•°æ®æ‰¹é‡å†™å…¥æ•°æ®åº“ï¼ˆå•ä¸ªå¤§äº‹åŠ¡ï¼‰
	flushBuffer := func(buf []model.MediaCache) error {
		if len(buf) == 0 {
			return nil
		}
		// ä½¿ç”¨äº‹åŠ¡åŒ…è£¹æ•´ä¸ªæ‰¹æ¬¡å†™å…¥ï¼Œå‡å°‘ fsync æ¬¡æ•°
		return s.DB.Transaction(func(tx *gorm.DB) error {
			// åˆ†æ‰¹å†™å…¥ï¼Œæ¯æ‰¹ 1000 æ¡ï¼Œé¿å… SQLite å˜é‡æ•°é™åˆ¶
			const dbBatch = 1000
			for i := 0; i < len(buf); i += dbBatch {
				end := i + dbBatch
				if end > len(buf) {
					end = len(buf)
				}
				if err := tx.Create(buf[i:end]).Error; err != nil {
					return fmt.Errorf("æ‰¹é‡å†™å…¥åª’ä½“ç¼“å­˜å¤±è´¥ (batch %d-%d): %w", i, end, err)
				}
			}
			return nil
		})
	}

	// åˆ†é¡µè·å–æ‰€æœ‰åª’ä½“æ¡ç›®ï¼Œä½¿ç”¨å¤§é¡µé¢å‡å°‘ HTTP è¯·æ±‚ï¼ˆåªæ‹‰å– Movie/Series/Episodeï¼‰
	err := client.GetMediaItemsWithContext(ctx, emby.SyncItemTypes, func(items []emby.MediaItem) error {
		for _, item := range items {
			// å†…å­˜å»é‡
			if seen[item.ID] {
				continue
			}
			seen[item.ID] = true

			cache := model.NewMediaCacheFromItem(item, "")
			buffer = append(buffer, cache)
		}

		// ç¼“å†²åŒºæ»¡æ—¶æ‰¹é‡å†™å…¥
		if len(buffer) >= syncBatchSize {
			if err := flushBuffer(buffer); err != nil {
				log.Printf("âš ï¸ æ‰¹é‡å†™å…¥å¤±è´¥: %v", err)
				return err
			}
			result.TotalItems += len(buffer)
			log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜åŒæ­¥: å·²å†™å…¥ %d ä¸ªæ¡ç›® (å»é‡å)...", result.TotalItems)
			buffer = buffer[:0] // æ¸…ç©ºç¼“å†²åŒºï¼Œå¤ç”¨åº•å±‚æ•°ç»„
		}

		return nil
	})

	if err != nil {
		return nil, fmt.Errorf("è·å– Emby åª’ä½“æ¡ç›®å¤±è´¥: %w", err)
	}

	// å†™å…¥å‰©ä½™ç¼“å†²åŒºæ•°æ®
	if len(buffer) > 0 {
		if err := flushBuffer(buffer); err != nil {
			return nil, fmt.Errorf("å†™å…¥å‰©ä½™åª’ä½“ç¼“å­˜å¤±è´¥: %w", err)
		}
		result.TotalItems += len(buffer)
	}

	log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜å†™å…¥å®Œæˆ: å…± %d ä¸ªæ¡ç›® (å»é‡å‰ %d ä¸ª)",
		result.TotalItems, len(seen))

	// ç›´æ¥ä»å·²åŒæ­¥çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜ï¼ˆé›¶é¢å¤– HTTP è¯·æ±‚ï¼‰
	sqlDB, err := s.DB.DB()
	if err != nil {
		log.Printf("âš ï¸ è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err)
	} else {
		seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
		if err != nil {
			log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
		} else {
			result.TotalSeasons = seasonCount
		}
	}

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… åª’ä½“ç¼“å­˜åŒæ­¥å®Œæˆ: %d ä¸ªåª’ä½“æ¡ç›®, %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.TotalSeasons, result.ElapsedMs)

	return result, nil
}

// SyncMediaCacheWithProgress å¸¦è¿›åº¦å›è°ƒçš„ç¼“å­˜åŒæ­¥
// ä¼˜åŒ–ç­–ç•¥ï¼š
//   - æµæ°´çº¿ï¼šAPI æ‹‰å–å’Œ DB å†™å…¥åœ¨ä¸åŒ goroutine å¹¶è¡Œ
//   - åŸç”Ÿ SQL prepared statement æ‰¹é‡å†™å…¥ï¼Œç»•è¿‡ GORM å¼€é”€
//   - å†…å­˜å»é‡é¿å… Emby API è·¨é¡µè¿”å›çš„é‡å¤æ¡ç›®
//   - åŒæ­¥å‰ DROP INDEX + é¢å¤– pragma ä¼˜åŒ–ï¼ŒåŒæ­¥åæ¢å¤
//   - å­£ç¼“å­˜å†™å…¥å‰å»é‡ï¼Œä½¿ç”¨åŸç”Ÿ SQL æ‰¹é‡å†™å…¥
func (s *CacheService) SyncMediaCacheWithProgress(ctx context.Context, client *emby.Client, progressCh chan<- SyncProgress) {
	defer close(progressCh)
	start := time.Now()

	sendError := func(msg string) {
		select {
		case progressCh <- SyncProgress{Phase: "media", Error: msg}:
		case <-ctx.Done():
		}
	}

	select {
	case <-ctx.Done():
		sendError("åŒæ­¥å·²å–æ¶ˆ")
		return
	default:
	}

	// è·å–åº•å±‚ *sql.DB ç”¨äºåŸç”Ÿ SQL æ“ä½œ
	sqlDB, err := s.DB.DB()
	if err != nil {
		sendError(fmt.Sprintf("è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err))
		return
	}

	// æ¸…ç©ºç¼“å­˜è¡¨
	if err := s.DB.Exec("DELETE FROM media_caches").Error; err != nil {
		sendError(fmt.Sprintf("æ¸…ç©ºåª’ä½“ç¼“å­˜è¡¨å¤±è´¥: %v", err))
		return
	}
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		sendError(fmt.Sprintf("æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %v", err))
		return
	}
	log.Printf("ğŸ—‘ï¸ å·²æ¸…ç©ºç¼“å­˜è¡¨")

	// åŒæ­¥å‰åˆ é™¤ç´¢å¼• + é¢å¤–å†™å…¥ä¼˜åŒ– pragma
	s.DB.Exec("DROP INDEX IF EXISTS idx_media_cache_emby_item_id")
	s.DB.Exec("PRAGMA temp_store=MEMORY")
	s.DB.Exec("PRAGMA mmap_size=268435456") // 256MB mmap

	// è·å–åª’ä½“æ€»æ•°
	total, err := client.GetTotalItemCount(ctx)
	if err != nil {
		log.Printf("âš ï¸ è·å–åª’ä½“æ€»æ•°å¤±è´¥ï¼Œä½¿ç”¨ 0: %v", err)
		total = 0
	}

	// å‘é€åˆå§‹è¿›åº¦
	select {
	case progressCh <- SyncProgress{Phase: "media", Processed: 0, Total: total}:
	case <-ctx.Done():
		sendError("åŒæ­¥å·²å–æ¶ˆ")
		return
	}

	result := &SyncResult{}

	// å†…å­˜å»é‡é›†åˆ
	seen := make(map[string]bool, 300000)

	// æµæ°´çº¿ï¼šwriteCh è¿æ¥ API æ‹‰å–å’Œ DB å†™å…¥
	type writeBatch struct {
		items []model.MediaCache
	}
	writeCh := make(chan writeBatch, 3) // ç¼“å†² 3 ä¸ªæ‰¹æ¬¡ï¼Œè®© API æ‹‰å–ä¸ç­‰ DB å†™å…¥
	writeErrCh := make(chan error, 1)

	// DB å†™å…¥ goroutine
	go func() {
		defer close(writeErrCh)
		for batch := range writeCh {
			if err := rawInsertMediaCaches(sqlDB, batch.items); err != nil {
				writeErrCh <- err
				return
			}
		}
	}()

	// å†…å­˜ç¼“å†²åŒº
	buffer := make([]model.MediaCache, 0, syncBatchSize)

	// åˆ†é¡µè·å–æ‰€æœ‰åª’ä½“æ¡ç›®ï¼ˆå†…å­˜å»é‡ï¼Œåªæ‹‰å– Movie/Series/Episodeï¼‰
	err = client.GetMediaItemsWithContext(ctx, emby.SyncItemTypes, func(items []emby.MediaItem) error {
		for _, item := range items {
			if seen[item.ID] {
				continue
			}
			seen[item.ID] = true

			cache := model.NewMediaCacheFromItem(item, "")
			buffer = append(buffer, cache)
		}

		// ç¼“å†²åŒºæ»¡æ—¶å‘é€åˆ°å†™å…¥é€šé“
		if len(buffer) >= syncBatchSize {
			// å¤åˆ¶ä¸€ä»½å‘é€ï¼Œé¿å…æ•°æ®ç«äº‰
			batch := make([]model.MediaCache, len(buffer))
			copy(batch, buffer)

			select {
			case writeCh <- writeBatch{items: batch}:
			case err := <-writeErrCh:
				return fmt.Errorf("DB å†™å…¥å¤±è´¥: %w", err)
			case <-ctx.Done():
				return ctx.Err()
			}

			result.TotalItems += len(buffer)
			log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜åŒæ­¥: å·²å¤„ç† %d ä¸ªæ¡ç›®...", result.TotalItems)
			buffer = buffer[:0]

			select {
			case progressCh <- SyncProgress{Phase: "media", Processed: result.TotalItems, Total: total}:
			case <-ctx.Done():
				return ctx.Err()
			}
		}

		return nil
	})

	if err != nil {
		close(writeCh)
		sendError(fmt.Sprintf("è·å– Emby åª’ä½“æ¡ç›®å¤±è´¥: %v", err))
		s.DB.Exec("CREATE UNIQUE INDEX IF NOT EXISTS idx_media_cache_emby_item_id ON media_caches(emby_item_id)")
		return
	}

	// å†™å…¥å‰©ä½™ç¼“å†²åŒº
	if len(buffer) > 0 {
		select {
		case writeCh <- writeBatch{items: buffer}:
		case err := <-writeErrCh:
			close(writeCh)
			sendError(fmt.Sprintf("DB å†™å…¥å¤±è´¥: %v", err))
			s.DB.Exec("CREATE UNIQUE INDEX IF NOT EXISTS idx_media_cache_emby_item_id ON media_caches(emby_item_id)")
			return
		}
		result.TotalItems += len(buffer)
	}

	// å…³é—­å†™å…¥é€šé“ï¼Œç­‰å¾…å†™å…¥å®Œæˆ
	close(writeCh)
	if err := <-writeErrCh; err != nil {
		sendError(fmt.Sprintf("DB å†™å…¥å¤±è´¥: %v", err))
		s.DB.Exec("CREATE UNIQUE INDEX IF NOT EXISTS idx_media_cache_emby_item_id ON media_caches(emby_item_id)")
		return
	}

	// å‘é€æœ€ç»ˆåª’ä½“è¿›åº¦
	select {
	case progressCh <- SyncProgress{Phase: "media", Processed: result.TotalItems, Total: total}:
	case <-ctx.Done():
	}

	log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜å†™å…¥å®Œæˆ: å…± %d ä¸ªæ¡ç›® (å»é‡å‰ API è¿”å› %d ä¸ª)", result.TotalItems, len(seen))

	// é‡å»ºç´¢å¼•
	if err := s.DB.Exec("CREATE UNIQUE INDEX IF NOT EXISTS idx_media_cache_emby_item_id ON media_caches(emby_item_id)").Error; err != nil {
		log.Printf("âš ï¸ é‡å»ºç´¢å¼•å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: %v", err)
	}

	// ç›´æ¥ä»å·²åŒæ­¥çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜ï¼ˆé›¶é¢å¤– HTTP è¯·æ±‚ï¼‰
	seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
	if err != nil {
		log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
	} else {
		result.TotalSeasons = seasonCount
	}

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… åª’ä½“ç¼“å­˜åŒæ­¥å®Œæˆ: %d ä¸ªåª’ä½“æ¡ç›®, %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.TotalSeasons, result.ElapsedMs)

	select {
	case progressCh <- SyncProgress{Phase: "done", Done: true, Processed: result.TotalItems, Total: total, Result: result}:
	case <-ctx.Done():
	}
}

// rawInsertMediaCaches ä½¿ç”¨åŸç”Ÿ SQL prepared statement æ‰¹é‡å†™å…¥åª’ä½“ç¼“å­˜
// æ¯” GORM Create å¿« 3-5 å€ï¼šé¢„ç¼–è¯‘è¯­å¥ + å¤šè¡Œ VALUES + å•äº‹åŠ¡
func rawInsertMediaCaches(db *sql.DB, items []model.MediaCache) error {
	if len(items) == 0 {
		return nil
	}

	tx, err := db.Begin()
	if err != nil {
		return err
	}
	defer tx.Rollback()

	// æ¯æ‰¹ 500 è¡Œï¼ˆ14 åˆ— Ã— 500 = 7000 å‚æ•°ï¼Œè¿œä½äº SQLite 32766 é™åˆ¶ï¼‰
	const cols = 14
	const batchRows = 500

	for i := 0; i < len(items); i += batchRows {
		end := i + batchRows
		if end > len(items) {
			end = len(items)
		}
		batch := items[i:end]

		// æ„å»º INSERT INTO ... VALUES (?,?,...), (?,?,...)
		var sb strings.Builder
		sb.WriteString("INSERT INTO media_caches (emby_item_id,name,type,has_poster,path,provider_ids,file_size,index_number,parent_index_number,child_count,series_id,series_name,library_name,cached_at) VALUES ")
		placeholder := "(?,?,?,?,?,?,?,?,?,?,?,?,?,?)"
		for j := range batch {
			if j > 0 {
				sb.WriteByte(',')
			}
			sb.WriteString(placeholder)
		}

		args := make([]interface{}, 0, len(batch)*cols)
		for _, c := range batch {
			args = append(args, c.EmbyItemID, c.Name, c.Type, c.HasPoster,
				c.Path, c.ProviderIDs, c.FileSize, c.IndexNumber, c.ParentIndexNumber, c.ChildCount,
				c.SeriesID, c.SeriesName, c.LibraryName, c.CachedAt)
		}

		if _, err := tx.Exec(sb.String(), args...); err != nil {
			return fmt.Errorf("æ‰¹é‡å†™å…¥å¤±è´¥ (rows %d-%d): %w", i, end, err)
		}
	}

	return tx.Commit()
}

// rawInsertSeasonCaches ä½¿ç”¨åŸç”Ÿ SQL æ‰¹é‡å†™å…¥å­£ç¼“å­˜
func rawInsertSeasonCaches(db *sql.DB, items []model.SeasonCache) error {
	if len(items) == 0 {
		return nil
	}

	tx, err := db.Begin()
	if err != nil {
		return err
	}
	defer tx.Rollback()

	const cols = 5
	const batchRows = 500

	for i := 0; i < len(items); i += batchRows {
		end := i + batchRows
		if end > len(items) {
			end = len(items)
		}
		batch := items[i:end]

		var sb strings.Builder
		sb.WriteString("INSERT INTO season_caches (series_emby_item_id,season_emby_item_id,season_number,episode_count,cached_at) VALUES ")
		placeholder := "(?,?,?,?,?)"
		for j := range batch {
			if j > 0 {
				sb.WriteByte(',')
			}
			sb.WriteString(placeholder)
		}

		args := make([]interface{}, 0, len(batch)*cols)
		for _, c := range batch {
			args = append(args, c.SeriesEmbyItemID, c.SeasonEmbyItemID, c.SeasonNumber, c.EpisodeCount, c.CachedAt)
		}

		if _, err := tx.Exec(sb.String(), args...); err != nil {
			return fmt.Errorf("æ‰¹é‡å†™å…¥å­£ç¼“å­˜å¤±è´¥ (rows %d-%d): %w", i, end, err)
		}
	}

	return tx.Commit()
}

// buildSeasonCacheFromEpisodes ä» media_caches ä¸­çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜
// æŒ‰ series_id + parent_index_number åˆ†ç»„ç»Ÿè®¡ Episode æ•°é‡ï¼Œç›´æ¥å†™å…¥ season_caches
// ä¸éœ€è¦ä»»ä½•é¢å¤–çš„ HTTP è¯·æ±‚ï¼Œå› ä¸º Episode æ•°æ®åœ¨åª’ä½“åŒæ­¥æ—¶å·²ç»æ‹‰å–
func (s *CacheService) buildSeasonCacheFromEpisodes(sqlDB *sql.DB) (int, error) {
	// ç”¨ä¸€æ¡ SQL èšåˆå‡ºæ¯ä¸ª Series æ¯å­£çš„ Episode æ•°é‡
	// series_id å¯¹åº” season_caches çš„ series_emby_item_id
	// parent_index_number å¯¹åº” season_number
	// season_emby_item_id ç”¨ series_id + '_S' + parent_index_number ç”Ÿæˆï¼ˆå› ä¸ºæ²¡æœ‰çœŸå®çš„ Season Emby IDï¼‰
	rows, err := sqlDB.Query(`
		SELECT series_id, parent_index_number, COUNT(*) as episode_count
		FROM media_caches
		WHERE type = 'Episode' AND series_id != ''
		GROUP BY series_id, parent_index_number
	`)
	if err != nil {
		return 0, fmt.Errorf("èšåˆ Episode æ•°æ®å¤±è´¥: %w", err)
	}
	defer rows.Close()

	// æ”¶é›†èšåˆç»“æœ
	type seasonAgg struct {
		seriesID     string
		seasonNumber int
		episodeCount int
	}
	var aggs []seasonAgg
	for rows.Next() {
		var a seasonAgg
		if err := rows.Scan(&a.seriesID, &a.seasonNumber, &a.episodeCount); err != nil {
			return 0, fmt.Errorf("è¯»å–èšåˆç»“æœå¤±è´¥: %w", err)
		}
		aggs = append(aggs, a)
	}
	if err := rows.Err(); err != nil {
		return 0, fmt.Errorf("éå†èšåˆç»“æœå¤±è´¥: %w", err)
	}

	if len(aggs) == 0 {
		return 0, nil
	}

	// æ‰¹é‡å†™å…¥ season_caches
	tx, err := sqlDB.Begin()
	if err != nil {
		return 0, fmt.Errorf("å¼€å¯äº‹åŠ¡å¤±è´¥: %w", err)
	}
	defer tx.Rollback()

	const batchRows = 500
	now := time.Now()

	for i := 0; i < len(aggs); i += batchRows {
		end := i + batchRows
		if end > len(aggs) {
			end = len(aggs)
		}
		batch := aggs[i:end]

		var sb strings.Builder
		sb.WriteString("INSERT INTO season_caches (series_emby_item_id, season_emby_item_id, season_number, episode_count, cached_at) VALUES ")
		placeholder := "(?,?,?,?,?)"
		for j := range batch {
			if j > 0 {
				sb.WriteByte(',')
			}
			sb.WriteString(placeholder)
		}

		args := make([]interface{}, 0, len(batch)*5)
		for _, a := range batch {
			// ç”Ÿæˆè™šæ‹Ÿçš„ season_emby_item_idï¼ˆå› ä¸ºä¸å†ä» Emby API è·å–çœŸå® Season IDï¼‰
			seasonEmbyID := fmt.Sprintf("%s_S%d", a.seriesID, a.seasonNumber)
			args = append(args, a.seriesID, seasonEmbyID, a.seasonNumber, a.episodeCount, now)
		}

		if _, err := tx.Exec(sb.String(), args...); err != nil {
			return 0, fmt.Errorf("æ‰¹é‡å†™å…¥å­£ç¼“å­˜å¤±è´¥ (rows %d-%d): %w", i, end, err)
		}
	}

	if err := tx.Commit(); err != nil {
		return 0, fmt.Errorf("æäº¤äº‹åŠ¡å¤±è´¥: %w", err)
	}

	log.Printf("ğŸ“Š ä» Episode èšåˆç”Ÿæˆäº† %d æ¡å­£ç¼“å­˜è®°å½•", len(aggs))
	return len(aggs), nil
}

// GetCacheStatus è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯
func (s *CacheService) GetCacheStatus() (*model.CacheStatus, error) {
	status := &model.CacheStatus{}

	// æŸ¥è¯¢åª’ä½“ç¼“å­˜æ¡ç›®æ•°
	if err := s.DB.Model(&model.MediaCache{}).Count(&status.TotalItems).Error; err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢åª’ä½“ç¼“å­˜æ¡ç›®æ•°å¤±è´¥: %w", err)
	}

	// æŸ¥è¯¢å­£ç¼“å­˜æ¡ç›®æ•°
	if err := s.DB.Model(&model.SeasonCache{}).Count(&status.TotalSeasons).Error; err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢å­£ç¼“å­˜æ¡ç›®æ•°å¤±è´¥: %w", err)
	}

	// æŸ¥è¯¢æœ€ååŒæ­¥æ—¶é—´
	var lastCache model.MediaCache
	if err := s.DB.Order("cached_at DESC").First(&lastCache).Error; err == nil {
		status.LastSyncAt = &lastCache.CachedAt
	}

	return status, nil
}
