package service

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"strings"
	"time"

	"embyforge/internal/emby"
	"embyforge/internal/model"

	"gorm.io/gorm"
	"gorm.io/gorm/clause"
)

// SyncResult åŒæ­¥ç»“æœ
type SyncResult struct {
	TotalItems   int   `json:"total_items"`
	TotalSeasons int   `json:"total_seasons"`
	ElapsedMs    int64 `json:"elapsed_ms"`
	NewItems     int   `json:"new_items"`     // å¢é‡åŒæ­¥ï¼šæ–°å¢æ¡ç›®æ•°
	UpdatedItems int   `json:"updated_items"` // å¢é‡åŒæ­¥ï¼šæ›´æ–°æ¡ç›®æ•°
	DeletedItems int   `json:"deleted_items"` // å¢é‡åŒæ­¥ï¼šåˆ é™¤æ¡ç›®æ•°
	IsIncremental bool `json:"is_incremental"` // æ˜¯å¦ä¸ºå¢é‡åŒæ­¥
}

// SyncProgress åŒæ­¥è¿›åº¦äº‹ä»¶
type SyncProgress struct {
	Phase     string      `json:"phase"`               // "media" æˆ– "season"
	Processed int         `json:"processed"`            // å·²å¤„ç†æ¡ç›®æ•°
	Total     int         `json:"total"`                // æ€»æ¡ç›®æ•°
	Done      bool        `json:"done"`                 // æ˜¯å¦å®Œæˆ
	Error     string      `json:"error,omitempty"`      // é”™è¯¯ä¿¡æ¯
	Result    *SyncResult `json:"result,omitempty"`     // å®Œæˆæ—¶çš„ç»“æœ
}

// CacheService åª’ä½“ç¼“å­˜æœåŠ¡
type CacheService struct {
	DB *gorm.DB
}

// NewCacheService åˆ›å»ºç¼“å­˜æœåŠ¡
func NewCacheService(db *gorm.DB) *CacheService {
	return &CacheService{DB: db}
}

// SyncMediaCache ä» Emby åŒæ­¥å®Œæ•´åª’ä½“åº“åˆ°æœ¬åœ°ç¼“å­˜
// æµç¨‹ï¼šæ¸…ç©ºç¼“å­˜è¡¨ â†’ åˆ†é¡µè·å– Emby åª’ä½“ â†’ æ‰¹é‡å†™å…¥ media_cache â†’ è·å– Series çš„å­£ä¿¡æ¯ â†’ å†™å…¥ season_cache
func (s *CacheService) SyncMediaCache(client *emby.Client) (*SyncResult, error) {
	start := time.Now()

	// æ¸…ç©ºç¼“å­˜è¡¨
	if err := s.DB.Exec("DELETE FROM media_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºåª’ä½“ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	log.Printf("ğŸ—‘ï¸ å·²æ¸…ç©ºç¼“å­˜è¡¨")

	result := &SyncResult{}

	// åˆ†é¡µè·å–æ‰€æœ‰åª’ä½“æ¡ç›®å¹¶å†™å…¥ç¼“å­˜ï¼ˆåªæ‹‰å– Movie/Series/Episodeï¼‰
	err := client.GetMediaItems(emby.SyncItemTypes, func(items []emby.MediaItem) error {
		caches := make([]model.MediaCache, 0, len(items))
		for _, item := range items {
			cache := model.NewMediaCacheFromItem(item, "")
			caches = append(caches, cache)
		}

		if len(caches) > 0 {
			if err := s.DB.Clauses(clause.OnConflict{
				Columns:   []clause.Column{{Name: "emby_item_id"}},
				DoUpdates: clause.AssignmentColumns([]string{"name", "type", "has_poster", "path", "provider_ids", "file_size", "index_number", "parent_index_number", "child_count", "series_id", "series_name", "library_name", "cached_at"}),
			}).Create(&caches).Error; err != nil {
				log.Printf("æ‰¹é‡å†™å…¥åª’ä½“ç¼“å­˜å¤±è´¥ï¼Œå°è¯•é€æ¡å†™å…¥: %v", err)
				for _, c := range caches {
					if err := s.DB.Clauses(clause.OnConflict{
						Columns:   []clause.Column{{Name: "emby_item_id"}},
						DoUpdates: clause.AssignmentColumns([]string{"name", "type", "has_poster", "path", "provider_ids", "file_size", "index_number", "parent_index_number", "child_count", "series_id", "series_name", "library_name", "cached_at"}),
					}).Create(&c).Error; err != nil {
						log.Printf("å†™å…¥åª’ä½“ç¼“å­˜è®°å½•å¤±è´¥ (EmbyItemID=%s): %v", c.EmbyItemID, err)
						continue
					}
				}
			}
			result.TotalItems += len(caches)
		}

		log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜åŒæ­¥: å·²å¤„ç† %d ä¸ªæ¡ç›®...", result.TotalItems)
		return nil
	})

	if err != nil {
		return nil, fmt.Errorf("è·å– Emby åª’ä½“æ¡ç›®å¤±è´¥: %w", err)
	}

	// ç›´æ¥ä»å·²åŒæ­¥çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜ï¼ˆé›¶é¢å¤– HTTP è¯·æ±‚ï¼‰
	sqlDB, dbErr := s.DB.DB()
	if dbErr != nil {
		log.Printf("âš ï¸ è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", dbErr)
	} else {
		seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
		if err != nil {
			log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
		} else {
			result.TotalSeasons = seasonCount
		}
	}

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… åª’ä½“ç¼“å­˜åŒæ­¥å®Œæˆ: %d ä¸ªåª’ä½“æ¡ç›®, %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.TotalSeasons, result.ElapsedMs)

	return result, nil
}

// syncBatchSize å†…å­˜ç¼“å†²åŒºæ»¡åæ‰¹é‡å†™å…¥æ•°æ®åº“çš„æ¡ç›®æ•°
const syncBatchSize = 10000

// SyncMediaCacheWithContext ä½¿ç”¨ Worker Pool çš„ç¼“å­˜åŒæ­¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰
// ä¼˜åŒ–ç­–ç•¥ï¼š
//   - å¢å¤§ API é¡µé¢å¤§å°å‡å°‘ HTTP è¯·æ±‚æ¬¡æ•°
//   - å†…å­˜å»é‡é¿å… Emby API è¿”å›çš„é‡å¤æ¡ç›®
//   - å…ˆ DELETE å†çº¯ INSERTï¼ˆæ— éœ€ ON CONFLICT å¼€é”€ï¼‰
//   - å¤§æ‰¹é‡äº‹åŠ¡å†™å…¥å‡å°‘ SQLite äº‹åŠ¡å¼€é”€
func (s *CacheService) SyncMediaCacheWithContext(ctx context.Context, client *emby.Client) (*SyncResult, error) {
	start := time.Now()

	// æ£€æŸ¥ context æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return nil, ctx.Err()
	default:
	}

	// æ¸…ç©ºç¼“å­˜è¡¨
	if err := s.DB.Exec("DELETE FROM media_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºåª’ä½“ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		return nil, fmt.Errorf("æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %w", err)
	}
	log.Printf("ğŸ—‘ï¸ å·²æ¸…ç©ºç¼“å­˜è¡¨")

	result := &SyncResult{}

	// å†…å­˜å»é‡é›†åˆï¼ŒEmby API è·¨é¡µå¯èƒ½è¿”å›é‡å¤ item
	seen := make(map[string]bool, 300000)
	// å†…å­˜ç¼“å†²åŒºï¼Œæ”’å¤Ÿ syncBatchSize æ¡åæ‰¹é‡å†™å…¥
	buffer := make([]model.MediaCache, 0, syncBatchSize)

	// flushBuffer å°†ç¼“å†²åŒºæ•°æ®æ‰¹é‡å†™å…¥æ•°æ®åº“ï¼ˆå•ä¸ªå¤§äº‹åŠ¡ï¼‰
	flushBuffer := func(buf []model.MediaCache) error {
		if len(buf) == 0 {
			return nil
		}
		// ä½¿ç”¨äº‹åŠ¡åŒ…è£¹æ•´ä¸ªæ‰¹æ¬¡å†™å…¥ï¼Œå‡å°‘ fsync æ¬¡æ•°
		return s.DB.Transaction(func(tx *gorm.DB) error {
			// åˆ†æ‰¹å†™å…¥ï¼Œæ¯æ‰¹ 1000 æ¡ï¼Œé¿å… SQLite å˜é‡æ•°é™åˆ¶
			const dbBatch = 1000
			for i := 0; i < len(buf); i += dbBatch {
				end := i + dbBatch
				if end > len(buf) {
					end = len(buf)
				}
				if err := tx.Create(buf[i:end]).Error; err != nil {
					return fmt.Errorf("æ‰¹é‡å†™å…¥åª’ä½“ç¼“å­˜å¤±è´¥ (batch %d-%d): %w", i, end, err)
				}
			}
			return nil
		})
	}

	// åˆ†é¡µè·å–æ‰€æœ‰åª’ä½“æ¡ç›®ï¼Œä½¿ç”¨å¤§é¡µé¢å‡å°‘ HTTP è¯·æ±‚ï¼ˆåªæ‹‰å– Movie/Series/Episodeï¼‰
	err := client.GetMediaItemsWithContext(ctx, emby.SyncItemTypes, func(items []emby.MediaItem) error {
		for _, item := range items {
			// å†…å­˜å»é‡
			if seen[item.ID] {
				continue
			}
			seen[item.ID] = true

			cache := model.NewMediaCacheFromItem(item, "")
			buffer = append(buffer, cache)
		}

		// ç¼“å†²åŒºæ»¡æ—¶æ‰¹é‡å†™å…¥
		if len(buffer) >= syncBatchSize {
			if err := flushBuffer(buffer); err != nil {
				log.Printf("âš ï¸ æ‰¹é‡å†™å…¥å¤±è´¥: %v", err)
				return err
			}
			result.TotalItems += len(buffer)
			log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜åŒæ­¥: å·²å†™å…¥ %d ä¸ªæ¡ç›® (å»é‡å)...", result.TotalItems)
			buffer = buffer[:0] // æ¸…ç©ºç¼“å†²åŒºï¼Œå¤ç”¨åº•å±‚æ•°ç»„
		}

		return nil
	})

	if err != nil {
		return nil, fmt.Errorf("è·å– Emby åª’ä½“æ¡ç›®å¤±è´¥: %w", err)
	}

	// å†™å…¥å‰©ä½™ç¼“å†²åŒºæ•°æ®
	if len(buffer) > 0 {
		if err := flushBuffer(buffer); err != nil {
			return nil, fmt.Errorf("å†™å…¥å‰©ä½™åª’ä½“ç¼“å­˜å¤±è´¥: %w", err)
		}
		result.TotalItems += len(buffer)
	}

	log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜å†™å…¥å®Œæˆ: å…± %d ä¸ªæ¡ç›® (å»é‡å‰ %d ä¸ª)",
		result.TotalItems, len(seen))

	// ç›´æ¥ä»å·²åŒæ­¥çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜ï¼ˆé›¶é¢å¤– HTTP è¯·æ±‚ï¼‰
	sqlDB, err := s.DB.DB()
	if err != nil {
		log.Printf("âš ï¸ è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err)
	} else {
		seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
		if err != nil {
			log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
		} else {
			result.TotalSeasons = seasonCount
		}
	}

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… åª’ä½“ç¼“å­˜åŒæ­¥å®Œæˆ: %d ä¸ªåª’ä½“æ¡ç›®, %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.TotalSeasons, result.ElapsedMs)

	return result, nil
}

// SyncMediaCacheWithProgress å¸¦è¿›åº¦å›è°ƒçš„ç¼“å­˜åŒæ­¥
// ä¼˜åŒ–ç­–ç•¥ï¼š
//   - æµæ°´çº¿ï¼šAPI æ‹‰å–å’Œ DB å†™å…¥åœ¨ä¸åŒ goroutine å¹¶è¡Œ
//   - åŸç”Ÿ SQL prepared statement æ‰¹é‡å†™å…¥ï¼Œç»•è¿‡ GORM å¼€é”€
//   - å†…å­˜å»é‡é¿å… Emby API è·¨é¡µè¿”å›çš„é‡å¤æ¡ç›®
//   - åŒæ­¥å‰ DROP INDEX + é¢å¤– pragma ä¼˜åŒ–ï¼ŒåŒæ­¥åæ¢å¤
//   - å­£ç¼“å­˜å†™å…¥å‰å»é‡ï¼Œä½¿ç”¨åŸç”Ÿ SQL æ‰¹é‡å†™å…¥
func (s *CacheService) SyncMediaCacheWithProgress(ctx context.Context, client *emby.Client, progressCh chan<- SyncProgress) {
	defer close(progressCh)
	start := time.Now()

	sendError := func(msg string) {
		select {
		case progressCh <- SyncProgress{Phase: "media", Error: msg}:
		case <-ctx.Done():
		}
	}

	select {
	case <-ctx.Done():
		sendError("åŒæ­¥å·²å–æ¶ˆ")
		return
	default:
	}

	// è·å–åº•å±‚ *sql.DB ç”¨äºåŸç”Ÿ SQL æ“ä½œ
	sqlDB, err := s.DB.DB()
	if err != nil {
		sendError(fmt.Sprintf("è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err))
		return
	}

	// æ¸…ç©ºç¼“å­˜è¡¨
	if err := s.DB.Exec("DELETE FROM media_caches").Error; err != nil {
		sendError(fmt.Sprintf("æ¸…ç©ºåª’ä½“ç¼“å­˜è¡¨å¤±è´¥: %v", err))
		return
	}
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		sendError(fmt.Sprintf("æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %v", err))
		return
	}
	log.Printf("ğŸ—‘ï¸ å·²æ¸…ç©ºç¼“å­˜è¡¨")

	// åŒæ­¥å‰åˆ é™¤ç´¢å¼• + é¢å¤–å†™å…¥ä¼˜åŒ– pragmaï¼ˆå†™å…¥å®Œæˆåé‡å»ºï¼‰
	s.DB.Exec("DROP INDEX IF EXISTS idx_media_cache_emby_item_id")
	s.DB.Exec("DROP INDEX IF EXISTS idx_media_caches_type")
	s.DB.Exec("DROP INDEX IF EXISTS idx_media_caches_series_id")
	s.DB.Exec("PRAGMA temp_store=MEMORY")
	s.DB.Exec("PRAGMA mmap_size=268435456") // 256MB mmap

	// è·å–åª’ä½“æ€»æ•°
	total, err := client.GetTotalItemCount(ctx)
	if err != nil {
		log.Printf("âš ï¸ è·å–åª’ä½“æ€»æ•°å¤±è´¥ï¼Œä½¿ç”¨ 0: %v", err)
		total = 0
	}

	// å‘é€åˆå§‹è¿›åº¦
	select {
	case progressCh <- SyncProgress{Phase: "media", Processed: 0, Total: total}:
	case <-ctx.Done():
		sendError("åŒæ­¥å·²å–æ¶ˆ")
		return
	}

	result := &SyncResult{}

	// å†…å­˜å»é‡é›†åˆ
	seen := make(map[string]bool, 300000)

	// æµæ°´çº¿ï¼šwriteCh è¿æ¥ API æ‹‰å–å’Œ DB å†™å…¥
	type writeBatch struct {
		items []model.MediaCache
	}
	writeCh := make(chan writeBatch, 3) // ç¼“å†² 3 ä¸ªæ‰¹æ¬¡ï¼Œè®© API æ‹‰å–ä¸ç­‰ DB å†™å…¥
	writeErrCh := make(chan error, 1)

	// DB å†™å…¥ goroutine
	go func() {
		defer close(writeErrCh)
		for batch := range writeCh {
			if err := rawInsertMediaCaches(sqlDB, batch.items); err != nil {
				writeErrCh <- err
				return
			}
		}
	}()

	// å†…å­˜ç¼“å†²åŒº
	buffer := make([]model.MediaCache, 0, syncBatchSize)

	// åˆ†é¡µè·å–æ‰€æœ‰åª’ä½“æ¡ç›®ï¼ˆå†…å­˜å»é‡ï¼Œåªæ‹‰å– Movie/Series/Episodeï¼‰
	err = client.GetMediaItemsWithContext(ctx, emby.SyncItemTypes, func(items []emby.MediaItem) error {
		for _, item := range items {
			if seen[item.ID] {
				continue
			}
			seen[item.ID] = true

			cache := model.NewMediaCacheFromItem(item, "")
			buffer = append(buffer, cache)
		}

		// ç¼“å†²åŒºæ»¡æ—¶å‘é€åˆ°å†™å…¥é€šé“
		if len(buffer) >= syncBatchSize {
			// å¤åˆ¶ä¸€ä»½å‘é€ï¼Œé¿å…æ•°æ®ç«äº‰
			batch := make([]model.MediaCache, len(buffer))
			copy(batch, buffer)

			select {
			case writeCh <- writeBatch{items: batch}:
			case err := <-writeErrCh:
				return fmt.Errorf("DB å†™å…¥å¤±è´¥: %w", err)
			case <-ctx.Done():
				return ctx.Err()
			}

			result.TotalItems += len(buffer)
			log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜åŒæ­¥: å·²å¤„ç† %d ä¸ªæ¡ç›®...", result.TotalItems)
			buffer = buffer[:0]

			select {
			case progressCh <- SyncProgress{Phase: "media", Processed: result.TotalItems, Total: total}:
			case <-ctx.Done():
				return ctx.Err()
			}
		}

		return nil
	})

	if err != nil {
		close(writeCh)
		sendError(fmt.Sprintf("è·å– Emby åª’ä½“æ¡ç›®å¤±è´¥: %v", err))
		s.rebuildMediaCacheIndexes()
		return
	}

	// å†™å…¥å‰©ä½™ç¼“å†²åŒº
	if len(buffer) > 0 {
		select {
		case writeCh <- writeBatch{items: buffer}:
		case err := <-writeErrCh:
			close(writeCh)
			sendError(fmt.Sprintf("DB å†™å…¥å¤±è´¥: %v", err))
			s.rebuildMediaCacheIndexes()
			return
		}
		result.TotalItems += len(buffer)
	}

	// å…³é—­å†™å…¥é€šé“ï¼Œç­‰å¾…å†™å…¥å®Œæˆ
	close(writeCh)
	if err := <-writeErrCh; err != nil {
		sendError(fmt.Sprintf("DB å†™å…¥å¤±è´¥: %v", err))
		s.rebuildMediaCacheIndexes()
		return
	}

	// å‘é€æœ€ç»ˆåª’ä½“è¿›åº¦
	select {
	case progressCh <- SyncProgress{Phase: "media", Processed: result.TotalItems, Total: total}:
	case <-ctx.Done():
	}

	log.Printf("ğŸ“Š åª’ä½“ç¼“å­˜å†™å…¥å®Œæˆ: å…± %d ä¸ªæ¡ç›® (å»é‡å‰ API è¿”å› %d ä¸ª)", result.TotalItems, len(seen))

	// é‡å»ºç´¢å¼•
	s.rebuildMediaCacheIndexes()

	// ç›´æ¥ä»å·²åŒæ­¥çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜ï¼ˆé›¶é¢å¤– HTTP è¯·æ±‚ï¼‰
	seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
	if err != nil {
		log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
	} else {
		result.TotalSeasons = seasonCount
	}

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… åª’ä½“ç¼“å­˜åŒæ­¥å®Œæˆ: %d ä¸ªåª’ä½“æ¡ç›®, %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.TotalSeasons, result.ElapsedMs)

	select {
	case progressCh <- SyncProgress{Phase: "done", Done: true, Processed: result.TotalItems, Total: total, Result: result}:
	case <-ctx.Done():
	}
}

// rebuildMediaCacheIndexes é‡å»º media_caches è¡¨çš„æ‰€æœ‰ç´¢å¼•
func (s *CacheService) rebuildMediaCacheIndexes() {
	s.DB.Exec("CREATE UNIQUE INDEX IF NOT EXISTS idx_media_cache_emby_item_id ON media_caches(emby_item_id)")
	s.DB.Exec("CREATE INDEX IF NOT EXISTS idx_media_caches_type ON media_caches(type)")
	s.DB.Exec("CREATE INDEX IF NOT EXISTS idx_media_caches_series_id ON media_caches(series_id)")
}

// rawInsertMediaCaches ä½¿ç”¨åŸç”Ÿ SQL prepared statement æ‰¹é‡å†™å…¥åª’ä½“ç¼“å­˜
// æ¯” GORM Create å¿« 3-5 å€ï¼šé¢„ç¼–è¯‘è¯­å¥ + å¤šè¡Œ VALUES + å•äº‹åŠ¡
func rawInsertMediaCaches(db *sql.DB, items []model.MediaCache) error {
	if len(items) == 0 {
		return nil
	}

	tx, err := db.Begin()
	if err != nil {
		return err
	}
	defer tx.Rollback()

	// æ¯æ‰¹ 500 è¡Œï¼ˆ14 åˆ— Ã— 500 = 7000 å‚æ•°ï¼Œè¿œä½äº SQLite 32766 é™åˆ¶ï¼‰
	const cols = 14
	const batchRows = 500

	for i := 0; i < len(items); i += batchRows {
		end := i + batchRows
		if end > len(items) {
			end = len(items)
		}
		batch := items[i:end]

		// æ„å»º INSERT INTO ... VALUES (?,?,...), (?,?,...)
		var sb strings.Builder
		sb.WriteString("INSERT INTO media_caches (emby_item_id,name,type,has_poster,path,provider_ids,file_size,index_number,parent_index_number,child_count,series_id,series_name,library_name,cached_at) VALUES ")
		placeholder := "(?,?,?,?,?,?,?,?,?,?,?,?,?,?)"
		for j := range batch {
			if j > 0 {
				sb.WriteByte(',')
			}
			sb.WriteString(placeholder)
		}

		args := make([]interface{}, 0, len(batch)*cols)
		for _, c := range batch {
			args = append(args, c.EmbyItemID, c.Name, c.Type, c.HasPoster,
				c.Path, c.ProviderIDs, c.FileSize, c.IndexNumber, c.ParentIndexNumber, c.ChildCount,
				c.SeriesID, c.SeriesName, c.LibraryName, c.CachedAt)
		}

		if _, err := tx.Exec(sb.String(), args...); err != nil {
			return fmt.Errorf("æ‰¹é‡å†™å…¥å¤±è´¥ (rows %d-%d): %w", i, end, err)
		}
	}

	return tx.Commit()
}

// rawInsertSeasonCaches ä½¿ç”¨åŸç”Ÿ SQL æ‰¹é‡å†™å…¥å­£ç¼“å­˜
func rawInsertSeasonCaches(db *sql.DB, items []model.SeasonCache) error {
	if len(items) == 0 {
		return nil
	}

	tx, err := db.Begin()
	if err != nil {
		return err
	}
	defer tx.Rollback()

	const cols = 5
	const batchRows = 500

	for i := 0; i < len(items); i += batchRows {
		end := i + batchRows
		if end > len(items) {
			end = len(items)
		}
		batch := items[i:end]

		var sb strings.Builder
		sb.WriteString("INSERT INTO season_caches (series_emby_item_id,season_emby_item_id,season_number,episode_count,cached_at) VALUES ")
		placeholder := "(?,?,?,?,?)"
		for j := range batch {
			if j > 0 {
				sb.WriteByte(',')
			}
			sb.WriteString(placeholder)
		}

		args := make([]interface{}, 0, len(batch)*cols)
		for _, c := range batch {
			args = append(args, c.SeriesEmbyItemID, c.SeasonEmbyItemID, c.SeasonNumber, c.EpisodeCount, c.CachedAt)
		}

		if _, err := tx.Exec(sb.String(), args...); err != nil {
			return fmt.Errorf("æ‰¹é‡å†™å…¥å­£ç¼“å­˜å¤±è´¥ (rows %d-%d): %w", i, end, err)
		}
	}

	return tx.Commit()
}

// buildSeasonCacheFromEpisodes ä» media_caches ä¸­çš„ Episode æ•°æ®èšåˆç”Ÿæˆå­£ç¼“å­˜
// æŒ‰ series_id + parent_index_number åˆ†ç»„ç»Ÿè®¡ Episode æ•°é‡ï¼Œç›´æ¥å†™å…¥ season_caches
// ä¸éœ€è¦ä»»ä½•é¢å¤–çš„ HTTP è¯·æ±‚ï¼Œå› ä¸º Episode æ•°æ®åœ¨åª’ä½“åŒæ­¥æ—¶å·²ç»æ‹‰å–
func (s *CacheService) buildSeasonCacheFromEpisodes(sqlDB *sql.DB) (int, error) {
	// ç”¨ä¸€æ¡ SQL èšåˆå‡ºæ¯ä¸ª Series æ¯å­£çš„ Episode æ•°é‡
	// series_id å¯¹åº” season_caches çš„ series_emby_item_id
	// parent_index_number å¯¹åº” season_number
	// season_emby_item_id ç”¨ series_id + '_S' + parent_index_number ç”Ÿæˆï¼ˆå› ä¸ºæ²¡æœ‰çœŸå®çš„ Season Emby IDï¼‰
	rows, err := sqlDB.Query(`
		SELECT series_id, parent_index_number, COUNT(*) as episode_count
		FROM media_caches
		WHERE type = 'Episode' AND series_id != ''
		GROUP BY series_id, parent_index_number
	`)
	if err != nil {
		return 0, fmt.Errorf("èšåˆ Episode æ•°æ®å¤±è´¥: %w", err)
	}
	defer rows.Close()

	// æ”¶é›†èšåˆç»“æœ
	type seasonAgg struct {
		seriesID     string
		seasonNumber int
		episodeCount int
	}
	var aggs []seasonAgg
	for rows.Next() {
		var a seasonAgg
		if err := rows.Scan(&a.seriesID, &a.seasonNumber, &a.episodeCount); err != nil {
			return 0, fmt.Errorf("è¯»å–èšåˆç»“æœå¤±è´¥: %w", err)
		}
		aggs = append(aggs, a)
	}
	if err := rows.Err(); err != nil {
		return 0, fmt.Errorf("éå†èšåˆç»“æœå¤±è´¥: %w", err)
	}

	if len(aggs) == 0 {
		return 0, nil
	}

	// æ‰¹é‡å†™å…¥ season_caches
	tx, err := sqlDB.Begin()
	if err != nil {
		return 0, fmt.Errorf("å¼€å¯äº‹åŠ¡å¤±è´¥: %w", err)
	}
	defer tx.Rollback()

	const batchRows = 500
	now := time.Now()

	for i := 0; i < len(aggs); i += batchRows {
		end := i + batchRows
		if end > len(aggs) {
			end = len(aggs)
		}
		batch := aggs[i:end]

		var sb strings.Builder
		sb.WriteString("INSERT INTO season_caches (series_emby_item_id, season_emby_item_id, season_number, episode_count, cached_at) VALUES ")
		placeholder := "(?,?,?,?,?)"
		for j := range batch {
			if j > 0 {
				sb.WriteByte(',')
			}
			sb.WriteString(placeholder)
		}

		args := make([]interface{}, 0, len(batch)*5)
		for _, a := range batch {
			// ç”Ÿæˆè™šæ‹Ÿçš„ season_emby_item_idï¼ˆå› ä¸ºä¸å†ä» Emby API è·å–çœŸå® Season IDï¼‰
			seasonEmbyID := fmt.Sprintf("%s_S%d", a.seriesID, a.seasonNumber)
			args = append(args, a.seriesID, seasonEmbyID, a.seasonNumber, a.episodeCount, now)
		}

		if _, err := tx.Exec(sb.String(), args...); err != nil {
			return 0, fmt.Errorf("æ‰¹é‡å†™å…¥å­£ç¼“å­˜å¤±è´¥ (rows %d-%d): %w", i, end, err)
		}
	}

	if err := tx.Commit(); err != nil {
		return 0, fmt.Errorf("æäº¤äº‹åŠ¡å¤±è´¥: %w", err)
	}

	log.Printf("ğŸ“Š ä» Episode èšåˆç”Ÿæˆäº† %d æ¡å­£ç¼“å­˜è®°å½•", len(aggs))
	return len(aggs), nil
}

// IncrementalSyncMediaCacheWithProgress å¢é‡åŒæ­¥ï¼šåªåŒæ­¥æ–°å¢å’Œä¿®æ”¹çš„æ¡ç›®ï¼Œæ£€æµ‹å¹¶åˆ é™¤å·²ç§»é™¤çš„æ¡ç›®
// æµç¨‹ï¼š
//  1. è·å–ä¸Šæ¬¡åŒæ­¥æ—¶é—´ï¼ˆlast_sync_atï¼‰
//  2. å¦‚æœæ²¡æœ‰ä¸Šæ¬¡åŒæ­¥è®°å½• â†’ å›é€€åˆ°å…¨é‡åŒæ­¥
//  3. é€šè¿‡ MinDateLastSaved è·å–ä¿®æ”¹è¿‡çš„æ¡ç›® â†’ UPSERT åˆ°æœ¬åœ°ç¼“å­˜
//  4. è·å– Emby å½“å‰æ‰€æœ‰ ID â†’ åˆ é™¤æœ¬åœ°æœ‰ä½† Emby å·²ç§»é™¤çš„æ¡ç›®
//  5. é‡å»ºå­£ç¼“å­˜
func (s *CacheService) IncrementalSyncMediaCacheWithProgress(ctx context.Context, client *emby.Client, progressCh chan<- SyncProgress) {
	// æ³¨æ„ï¼šä¸ä½¿ç”¨ defer close(progressCh)ï¼Œå› ä¸ºå¯èƒ½å›é€€åˆ°å…¨é‡åŒæ­¥ï¼ˆç”±å…¨é‡æ–¹æ³•è´Ÿè´£ closeï¼‰

	// è·å–ä¸Šæ¬¡åŒæ­¥æ—¶é—´
	status, err := s.GetCacheStatus()
	if err != nil || status.LastSyncAt == nil || status.TotalItems == 0 {
		// æ²¡æœ‰ä¸Šæ¬¡åŒæ­¥è®°å½•ï¼Œå›é€€åˆ°å…¨é‡åŒæ­¥ï¼ˆå…¨é‡æ–¹æ³•ä¼šè´Ÿè´£ close progressChï¼‰
		log.Printf("ğŸ“Š æ²¡æœ‰ä¸Šæ¬¡åŒæ­¥è®°å½•ï¼Œå›é€€åˆ°å…¨é‡åŒæ­¥")
		s.SyncMediaCacheWithProgress(ctx, client, progressCh)
		return
	}

	// èµ°å¢é‡é€»è¾‘ï¼Œç”±æœ¬æ–¹æ³•è´Ÿè´£ close
	defer close(progressCh)
	start := time.Now()

	sendError := func(msg string) {
		select {
		case progressCh <- SyncProgress{Phase: "media", Error: msg}:
		case <-ctx.Done():
		}
	}

	sendProgress := func(phase string, processed, total int) {
		select {
		case progressCh <- SyncProgress{Phase: phase, Processed: processed, Total: total}:
		case <-ctx.Done():
		}
	}

	select {
	case <-ctx.Done():
		sendError("åŒæ­¥å·²å–æ¶ˆ")
		return
	default:
	}

	lastSyncAt := *status.LastSyncAt
	log.Printf("ğŸ”„ å¼€å§‹å¢é‡åŒæ­¥ï¼Œä¸Šæ¬¡åŒæ­¥æ—¶é—´: %s", lastSyncAt.Format(time.RFC3339))

	result := &SyncResult{IsIncremental: true}

	// é˜¶æ®µ 1ï¼šè·å–ä¿®æ”¹è¿‡çš„æ¡ç›®å¹¶ UPSERT
	sendProgress("media", 0, 0)

	processed := 0
	err = client.GetMediaItemsModifiedSince(ctx, lastSyncAt, emby.SyncItemTypes, func(items []emby.MediaItem) error {
		if len(items) == 0 {
			return nil
		}

		caches := make([]model.MediaCache, 0, len(items))
		for _, item := range items {
			cache := model.NewMediaCacheFromItem(item, "")
			caches = append(caches, cache)
		}

		// UPSERTï¼šå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥
		for _, c := range caches {
			var existing model.MediaCache
			dbResult := s.DB.Where("emby_item_id = ?", c.EmbyItemID).First(&existing)
			if dbResult.Error == nil {
				// å·²å­˜åœ¨ï¼Œæ›´æ–°
				if err := s.DB.Model(&existing).Updates(map[string]interface{}{
					"name":               c.Name,
					"type":               c.Type,
					"has_poster":         c.HasPoster,
					"path":               c.Path,
					"provider_ids":       c.ProviderIDs,
					"file_size":          c.FileSize,
					"index_number":       c.IndexNumber,
					"parent_index_number": c.ParentIndexNumber,
					"child_count":        c.ChildCount,
					"series_id":          c.SeriesID,
					"series_name":        c.SeriesName,
					"library_name":       c.LibraryName,
					"cached_at":          c.CachedAt,
				}).Error; err != nil {
					log.Printf("âš ï¸ æ›´æ–°ç¼“å­˜è®°å½•å¤±è´¥ (EmbyItemID=%s): %v", c.EmbyItemID, err)
					continue
				}
				result.UpdatedItems++
			} else {
				// ä¸å­˜åœ¨ï¼Œæ’å…¥
				if err := s.DB.Create(&c).Error; err != nil {
					log.Printf("âš ï¸ æ’å…¥ç¼“å­˜è®°å½•å¤±è´¥ (EmbyItemID=%s): %v", c.EmbyItemID, err)
					continue
				}
				result.NewItems++
			}
		}

		processed += len(items)
		sendProgress("media", processed, 0)
		log.Printf("ğŸ“Š å¢é‡åŒæ­¥: å·²å¤„ç† %d ä¸ªå˜æ›´æ¡ç›® (æ–°å¢: %d, æ›´æ–°: %d)",
			processed, result.NewItems, result.UpdatedItems)

		return nil
	})

	if err != nil {
		sendError(fmt.Sprintf("è·å–å¢é‡åª’ä½“æ¡ç›®å¤±è´¥: %v", err))
		return
	}

	log.Printf("ğŸ“Š å¢é‡å˜æ›´å¤„ç†å®Œæˆ: æ–°å¢ %d, æ›´æ–° %d", result.NewItems, result.UpdatedItems)

	// é˜¶æ®µ 2ï¼šåˆ é™¤æ£€æµ‹å·²ç”± WebSocket å®æ—¶ç›‘å¬å¤„ç†ï¼Œå¢é‡åŒæ­¥ä¸å†éœ€è¦
	// å¦‚éœ€ç²¾ç¡®æ¸…ç†ï¼Œè¯·ä½¿ç”¨å…¨é‡åŒæ­¥æ¨¡å¼

	// é˜¶æ®µ 3ï¼šé‡å»ºå­£ç¼“å­˜
	sendProgress("season", 0, 0)

	// æ¸…ç©ºå¹¶é‡å»ºå­£ç¼“å­˜
	if err := s.DB.Exec("DELETE FROM season_caches").Error; err != nil {
		log.Printf("âš ï¸ æ¸…ç©ºå­£ç¼“å­˜è¡¨å¤±è´¥: %v", err)
	} else {
		sqlDB, err := s.DB.DB()
		if err != nil {
			log.Printf("âš ï¸ è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err)
		} else {
			seasonCount, err := s.buildSeasonCacheFromEpisodes(sqlDB)
			if err != nil {
				log.Printf("âš ï¸ ä» Episode èšåˆç”Ÿæˆå­£ç¼“å­˜å¤±è´¥: %v", err)
			} else {
				result.TotalSeasons = seasonCount
			}
		}
	}

	// ç»Ÿè®¡æœ€ç»ˆæ€»æ•°
	var totalCount int64
	s.DB.Model(&model.MediaCache{}).Count(&totalCount)
	result.TotalItems = int(totalCount)

	result.ElapsedMs = time.Since(start).Milliseconds()
	log.Printf("âœ… å¢é‡åŒæ­¥å®Œæˆ: æ€»è®¡ %d æ¡ç›® (æ–°å¢ %d, æ›´æ–° %d, åˆ é™¤ %d), %d ä¸ªå­£, è€—æ—¶ %dms",
		result.TotalItems, result.NewItems, result.UpdatedItems, result.DeletedItems,
		result.TotalSeasons, result.ElapsedMs)

	select {
	case progressCh <- SyncProgress{Phase: "done", Done: true, Processed: result.TotalItems, Total: result.TotalItems, Result: result}:
	case <-ctx.Done():
	}
}

// GetCacheStatus è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯
func (s *CacheService) GetCacheStatus() (*model.CacheStatus, error) {
	status := &model.CacheStatus{}

	// æŸ¥è¯¢åª’ä½“ç¼“å­˜æ¡ç›®æ•°
	if err := s.DB.Model(&model.MediaCache{}).Count(&status.TotalItems).Error; err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢åª’ä½“ç¼“å­˜æ¡ç›®æ•°å¤±è´¥: %w", err)
	}

	// æŸ¥è¯¢å­£ç¼“å­˜æ¡ç›®æ•°
	if err := s.DB.Model(&model.SeasonCache{}).Count(&status.TotalSeasons).Error; err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢å­£ç¼“å­˜æ¡ç›®æ•°å¤±è´¥: %w", err)
	}

	// æŸ¥è¯¢æœ€ååŒæ­¥æ—¶é—´
	var lastCache model.MediaCache
	if err := s.DB.Order("cached_at DESC").First(&lastCache).Error; err == nil {
		status.LastSyncAt = &lastCache.CachedAt
	}

	return status, nil
}

// HandleLibraryChanged å¤„ç†åª’ä½“åº“å˜æ›´äº‹ä»¶
// ç”± LibraryWatcher å›è°ƒè§¦å‘ï¼Œç›´æ¥æ¥æ”¶å®Œæ•´çš„ MediaItemï¼ˆæ— éœ€äºŒæ¬¡è¯·æ±‚ï¼‰
func (s *CacheService) HandleLibraryChanged(ctx context.Context, client *emby.Client, items []emby.MediaItem, removed []string) {
	// å¤„ç†åˆ é™¤æ£€æµ‹ä¿¡å·
	if len(removed) == 1 && removed[0] == "__DETECT_DELETIONS__" {
		s.detectAndRemoveDeletedItems(ctx, client)
		removed = nil
	}

	// å¤„ç†æ™®é€šåˆ é™¤ï¼šç›´æ¥ä»æœ¬åœ°ç¼“å­˜ä¸­åˆ é™¤
	if len(removed) > 0 {
		const deleteBatch = 500
		for i := 0; i < len(removed); i += deleteBatch {
			end := i + deleteBatch
			if end > len(removed) {
				end = len(removed)
			}
			if err := s.DB.Where("emby_item_id IN ?", removed[i:end]).Delete(&model.MediaCache{}).Error; err != nil {
				log.Printf("âš ï¸ å®æ—¶åˆ é™¤ç¼“å­˜è®°å½•å¤±è´¥: %v", err)
			}
		}
		log.Printf("ğŸ—‘ï¸ å®æ—¶åŒæ­¥: å·²åˆ é™¤ %d ä¸ªç¼“å­˜æ¡ç›®", len(removed))
	}

	// å¤„ç†æ–°å¢å’Œæ›´æ–°ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å®Œæ•´ MediaItemï¼Œæ— éœ€å†è°ƒç”¨ GetItemByID
	if len(items) > 0 {
		newCount, updateCount := 0, 0
		for _, item := range items {
			// åªå¤„ç†æˆ‘ä»¬å…³å¿ƒçš„ç±»å‹
			if item.Type != "Movie" && item.Type != "Series" && item.Type != "Episode" {
				continue
			}

			cache := model.NewMediaCacheFromItem(item, "")
			var existing model.MediaCache
			if s.DB.Where("emby_item_id = ?", cache.EmbyItemID).First(&existing).Error == nil {
				// å·²å­˜åœ¨ï¼Œæ›´æ–°
				s.DB.Model(&existing).Updates(map[string]interface{}{
					"name":                cache.Name,
					"type":                cache.Type,
					"has_poster":          cache.HasPoster,
					"path":                cache.Path,
					"provider_ids":        cache.ProviderIDs,
					"file_size":           cache.FileSize,
					"index_number":        cache.IndexNumber,
					"parent_index_number": cache.ParentIndexNumber,
					"child_count":         cache.ChildCount,
					"series_id":           cache.SeriesID,
					"series_name":         cache.SeriesName,
					"library_name":        cache.LibraryName,
					"cached_at":           cache.CachedAt,
				})
				updateCount++
			} else {
				// ä¸å­˜åœ¨ï¼Œæ’å…¥
				if err := s.DB.Create(&cache).Error; err != nil {
					log.Printf("âš ï¸ å®æ—¶åŒæ­¥æ’å…¥ç¼“å­˜å¤±è´¥ (EmbyItemID=%s): %v", cache.EmbyItemID, err)
				}
				newCount++
			}
		}
		if newCount > 0 || updateCount > 0 {
			log.Printf("ğŸ“¡ å®æ—¶åŒæ­¥: æ–°å¢ %d, æ›´æ–° %d ä¸ªç¼“å­˜æ¡ç›®", newCount, updateCount)
		}
	}
}

// detectAndRemoveDeletedItems æ£€æµ‹å¹¶åˆ é™¤ Emby ä¸­å·²ä¸å­˜åœ¨çš„æœ¬åœ°ç¼“å­˜æ¡ç›®
// é€šè¿‡åˆ†é¡µè·å– Emby æ‰€æœ‰ IDï¼Œä¸æœ¬åœ°ç¼“å­˜å¯¹æ¯”ï¼Œåˆ é™¤æœ¬åœ°å¤šä½™çš„æ¡ç›®
func (s *CacheService) detectAndRemoveDeletedItems(ctx context.Context, client *emby.Client) {
	log.Printf("ğŸ” å¼€å§‹æ£€æµ‹å·²åˆ é™¤çš„æ¡ç›®...")

	embyIDs, total, err := client.GetAllItemIDs(ctx, emby.SyncItemTypes)
	if err != nil {
		log.Printf("âš ï¸ è·å– Emby ID åˆ—è¡¨å¤±è´¥: %v", err)
		return
	}

	// è·å–æœ¬åœ°æ‰€æœ‰ emby_item_id
	var localIDs []string
	if err := s.DB.Model(&model.MediaCache{}).Pluck("emby_item_id", &localIDs).Error; err != nil {
		log.Printf("âš ï¸ è·å–æœ¬åœ°ç¼“å­˜ ID åˆ—è¡¨å¤±è´¥: %v", err)
		return
	}

	// æ‰¾å‡ºæœ¬åœ°æœ‰ä½† Emby æ²¡æœ‰çš„æ¡ç›®
	var toDelete []string
	for _, id := range localIDs {
		if !embyIDs[id] {
			toDelete = append(toDelete, id)
		}
	}

	if len(toDelete) > 0 {
		const deleteBatch = 500
		for i := 0; i < len(toDelete); i += deleteBatch {
			end := i + deleteBatch
			if end > len(toDelete) {
				end = len(toDelete)
			}
			s.DB.Where("emby_item_id IN ?", toDelete[i:end]).Delete(&model.MediaCache{})
		}
		log.Printf("ğŸ—‘ï¸ åˆ é™¤æ£€æµ‹å®Œæˆ: åˆ é™¤äº† %d ä¸ªæœ¬åœ°å¤šä½™æ¡ç›® (Emby æ€»æ•°: %d, æœ¬åœ°åŸæœ‰: %d)",
			len(toDelete), total, len(localIDs))
	} else {
		log.Printf("âœ… åˆ é™¤æ£€æµ‹å®Œæˆ: æ— éœ€åˆ é™¤ (Emby: %d, æœ¬åœ°: %d)", total, len(localIDs))
	}
}
